{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CuU5ZQtb4Qc-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXfSY8mo4QdD"
   },
   "source": [
    "---\n",
    "# Part 3. Extract feature from texts and images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Jc_YQXt4QdF"
   },
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8pH4pkQP4QdF",
    "outputId": "905d010f-e4dc-426f-a9b3-b2cb62c05128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 8, 8)\n",
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset from sklearn\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits['images'].shape)\n",
    "print(digits['data'].shape)\n",
    "print(digits['target'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "n9SYNAM-4QdG",
    "outputId": "9ddbf417-3e6a-41d9-9aed-e1984426221f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# images contain 8x8 black'n'white pictures of hadwritten digits\n",
    "digits['images'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqlhH7tF4QdH"
   },
   "source": [
    "#### 1. Explore the data\n",
    "\n",
    "Let's plot several pictures, split dataset on train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CbaZ9y7g4QdH"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a plot\n",
    "_, axes = plt.subplots(3, 5)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, image, label in zip(axes, digits['images'], digits['target']):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r)\n",
    "    ax.set_title(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCkuzU7f4QdI"
   },
   "source": [
    "We will assume that each pixel is a feature. Note, that images were already rechaped into vectors for us in `digits['data']` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UkivG_hl4QdJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# perform train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits['data'], digits['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNezNu-g4QdK"
   },
   "source": [
    "#### 2. Train the model\n",
    "\n",
    "We can now train the model. This is a classification task with 10 classes. \n",
    "\n",
    "The model, that we will use is called `KNeighborsClassifier` (kNN). It does not have trainable parameters and works in the following manner:\n",
    "* Remember the training data\n",
    "* When new point arrives \n",
    "    * find `K` nearest points in the training dataset (e.g. by euclidean distance)\n",
    "    * return the most freaquent class among these `K`.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmoukJ2r4QdK"
   },
   "source": [
    "   Create and train the following pipeline:\n",
    "* Scale the input vectorized image \n",
    "* Classify by kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yEqBaOgi4QdL"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, StandardScaler()), (&#x27;clf&#x27;, KNeighborsClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, StandardScaler()), (&#x27;clf&#x27;, KNeighborsClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaling', StandardScaler()), ('clf', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# define pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('clf', KNeighborsClassifier())\n",
    "])\n",
    "# fit\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIH9wLQ64QdL"
   },
   "source": [
    "#### 3. Evaluate on test dataset\n",
    "\n",
    "We will use accuracy - proportion of correct predictions, to measure the quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VsZohRww4QdM"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# predict on test set\n",
    "y_pred = pipe.predict(X_test)\n",
    "# compute accuracy\n",
    "score = accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ywXnQUBu4QdM",
    "outputId": "c02e83c0-4377-44c2-d13d-fcd423f523cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sszKzt_4QdM"
   },
   "source": [
    "**Optional task**\n",
    "\n",
    "Implement accuracy youself usinf numpy only;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "dX6f9u7G4QdN"
   },
   "outputs": [],
   "source": [
    "def my_accuracy(true, predicted):\n",
    "    # your code here\n",
    "    pass\n",
    "    \n",
    "\n",
    "# test that your function work the same as `accuracy_score` from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDEsqWLh4QdN"
   },
   "source": [
    "---\n",
    "## Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7Z_GqsT4QdN"
   },
   "source": [
    "### 1.1 Convert documents to vectors\n",
    "\n",
    "Note that out dataset now is a set of documents (or texts): $D = (d_1, \\dots, d_N)$\n",
    "\n",
    "We will assume that there is vocabulary of size $M$, which contains all possible words, from which our documents are composed. \n",
    "\n",
    "Of course, each documents has different number of words in it. \n",
    "\n",
    "Today, we will consider 2 options how to represent texts with the vectors (embeddings):\n",
    "1. Bag of words\n",
    "2. Tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4mNRe_t4QdO"
   },
   "source": [
    "Let us firstly use the simplest example to undertand how both methods work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "F981PirV4QdO"
   },
   "outputs": [],
   "source": [
    "d1 = \"This is my favourite movie\"\n",
    "d2 = \"Is this movie boring? Yes, it is!\"\n",
    "d3 = \"This is an exiting movie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "K3Ba4fb74QdO",
    "outputId": "53cab14b-1097-40eb-87a9-17e0750476c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['this', 'is', 'my', 'favourite', 'movie'],\n",
       " ['is', 'this', 'movie', 'boring', 'yes', 'it', 'is'],\n",
       " ['this', 'is', 'an', 'exiting', 'movie']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "D = [re.sub('[.!?,]', '', d.lower()).split(' ') for d in [d1, d2, d3]]\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNOKR6Zi4QdP"
   },
   "source": [
    "The Vocabulary for such dataset would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Vfml28yB4QdP",
    "outputId": "f70224a2-489f-41b1-9377-007e55889106"
   },
   "outputs": [],
   "source": [
    "all_words = sum(D, [])\n",
    "V = list(set(all_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Et98iA24QdP"
   },
   "source": [
    "#### Option 1. Bag of words\n",
    "\n",
    "We can say, that text is charaterized by the vector of length $M$, which shows how many times each word from the vector is present in the document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d91Ihcsc4QdQ"
   },
   "source": [
    "Let us now calculate bag of words for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "6xja79zo4QdQ"
   },
   "outputs": [],
   "source": [
    "X =  np.zeros((len(D), len(V)))\n",
    "\n",
    "for j, v in enumerate(V):\n",
    "    for i, d in enumerate(D):\n",
    "        X[i, j] = sum([1 for w in d if w == v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "GW0YYb-O4QdQ",
    "outputId": "2adf5a6a-c73c-4160-fcef-93306903fe6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0., 0., 1., 1., 0., 0., 1.],\n",
       "       [0., 1., 1., 0., 1., 1., 2., 1., 0., 0.],\n",
       "       [0., 0., 1., 1., 0., 1., 1., 0., 1., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmepH6I64QdQ"
   },
   "source": [
    "#### Option 2. Tf-idf\n",
    "\n",
    "**Term Frequency times Inverce Document Frequency**\n",
    "\n",
    "A method to describe each document in the dataset with a vector of the same length. Takes into account, how often the word appears in the whole dataset.\n",
    "\n",
    "\n",
    "\n",
    "**Term frequency (tf)** - number of times a term occurs in a given document\n",
    "$$\n",
    "tf(t, d) = \\frac{\\# t \\text{ in } d}{len(d)}\n",
    "$$\n",
    "\n",
    "\n",
    "**Inverce document frequency (idf)** - measures informativeness of a term\n",
    "\n",
    "$$\n",
    "idf(t) = \\log \\frac{N}{(\\# d \\text{ with } t)} , N - \\text{ number of documents}\n",
    "$$\n",
    "\n",
    "If the word occures almost in all the documents (e.g. article, popular verb), then $idf$ will be very low.\n",
    "\n",
    "---\n",
    "Now we can covert each document onti the vector of size $M$:\n",
    "$$\n",
    "d \\rightarrow \\left(tf(t_1, d)\\cdot idf(t_1),\\,\\, \\dots, \\,\\, tf(t_M, d) \\cdot idf(t_M)\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "Let us calculate it for our simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "e0O5Sd3V4QdR",
    "outputId": "84a4a993-3e28-40f7-c733-31bd99f05e2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'my', 'favourite', 'movie'], ['is', 'this', 'movie', 'boring', 'yes', 'it', 'is'], ['this', 'is', 'an', 'exiting', 'movie']] \n",
      "\n",
      "['my', 'it', 'this', 'an', 'yes', 'movie', 'is', 'boring', 'exiting', 'favourite']\n"
     ]
    }
   ],
   "source": [
    "print(D, '\\n')\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "bcq9L9we4QdR"
   },
   "outputs": [],
   "source": [
    "# tf\n",
    "tf =  np.zeros((len(D), len(V)))\n",
    "\n",
    "for j, v in enumerate(V):\n",
    "    for i, d in enumerate(D):\n",
    "        tf[i, j] = sum([1 for w in d if w == v])/len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "dn5FjwWX4QdR"
   },
   "outputs": [],
   "source": [
    "#idf\n",
    "idf = np.zeros(len(V))\n",
    "\n",
    "for j, v in enumerate(V):\n",
    "    idf[j] = np.log(len(D) / sum([1 for d in D if v in d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "DlLOAI8l4QdR",
    "outputId": "ccc8db30-9daf-43db-ce42-3834b09051dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.22],\n",
       "       [0.  , 0.16, 0.  , 0.  , 0.16, 0.  , 0.  , 0.16, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.22, 0.  , 0.  , 0.  , 0.  , 0.22, 0.  ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf*idf\n",
    "np.round(X, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dx7JU9sD4QdR"
   },
   "source": [
    "---\n",
    "**Optional task**\n",
    "\n",
    "Below we will use `BoW` and `tf-idf` features to classify texts from the dataset with news articles. \n",
    "\n",
    "### BoW and Tf-Idf in Sklearn\n",
    "\n",
    "In practice, we can use `Trasfromers` from sklearn to get the same vector representation of texts as we implemented above. \n",
    "\n",
    "#### 1. Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1899,
     "status": "ok",
     "timestamp": 1663443597998,
     "user": {
      "displayName": "Маргарита Бурова",
      "userId": "08611594987469395240"
     },
     "user_tz": -180
    },
    "id": "A42p6sne4QdR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "categories = ['alt.atheism', 'sci.space']\n",
    "train = pd.read_csv('https://github.com/mbburova/MDS/raw/main/train_news.csv', index_col=0)\n",
    "X_train, y_train = train.news, train.target\n",
    "\n",
    "\n",
    "test = pd.read_csv('https://github.com/mbburova/MDS/raw/main/test_news.csv', index_col=0)\n",
    "X_test, y_test = test.news, test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpaSPdBP4QdS"
   },
   "source": [
    "#### 2. Explore the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9KYgGFp4QdS",
    "outputId": "9742029c-80fd-4919-debf-e5d9ab48896b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 0\n",
      ": \n",
      ": >> Please enlighten me.  How is omnipotence contradictory?\n",
      ": \n",
      ": >By definition, all that can occur in the universe is governed by the rules\n",
      ": >of nature. Thus god cannot break them. Anything that god does must be allowed\n",
      ": >in the rules somewhere. Therefore, omnipotence CANNOT exist! It contradicts\n",
      ": >the rules of nature.\n",
      ": \n",
      ": Obviously, an omnipotent god can change the rules.\n",
      "\n",
      "When you say, \"By definition\", what exactly is being defined;\n",
      "certainly not omnipotence. You seem to be saying that the \"rules of\n",
      "nature\" are pre-existant somehow, that they not only define nature but\n",
      "actually cause it. If that's what you mean I'd like to hear your\n",
      "further thoughts on the question.\n",
      "-------\n",
      "\n",
      "label: 1\n",
      "In <19APR199320262420@kelvin.jpl.nasa.gov> baalke@kelvin.jpl.nasa.gov \n",
      "\n",
      "Sorry I think I missed a bit of info on this Transition Experiment. What is it?\n",
      "\n",
      "Will this mean a loss of data or will the Magellan transmit data later on ??\n",
      "\n",
      "BTW: When will NASA cut off the connection with Magellan?? Not that I am\n",
      "looking forward to that day but I am just curious. I believe it had something\n",
      "to do with the funding from the goverment (or rather _NO_ funding :-)\n",
      "\n",
      "ok that's it for now. See you guys around,\n",
      "Jurriaan.\n",
      " \n",
      "-------\n",
      "\n",
      "label: 1\n",
      "\n",
      "Henry, I made the assumption that he who gets there firstest with the mostest\n",
      "wins. \n",
      "\n",
      "Ohhh, you want to put in FINE PRINT which says \"Thou shall do wonderous R&D\n",
      "rather than use off-the-shelf hardware\"? Sorry, didn't see that in my copy.\n",
      "Most of the Pournellesque proposals run along the lines of <some dollar\n",
      "amount> reward for <some simple goal>.  \n",
      "\n",
      "You go ahead and do your development, I'll buy off the shelf at higher cost (or\n",
      "even Russian; but I also assume that there'd be some \"Buy US\" provos in there)\n",
      "and be camped out in the Moon while you are launching and assembling little\n",
      "itty-bitty payloads in LEO with your laser or gas gun.  And working out the\n",
      "bugs of assembly & integration in LEO. \n",
      "\n",
      "Oh, hey, could I get a couple of CanadARMs tuned for the lunar environment?  I\n",
      "wanna do some teleoperated prospecting while I'm up there...\n",
      "\n",
      "\n",
      "\n",
      "-------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('label:',y_train[i])\n",
    "    print(X_train[i])\n",
    "    print('-------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-c1nD2jP4QdS"
   },
   "source": [
    "#### 3.1 BoW \n",
    "\n",
    "Our pipeline:\n",
    "* BoW vectorizer\n",
    "* kNN classifier\n",
    "\n",
    "We will use accuracy to evaluate model on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43ND2XcG4QdS"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTi9h2AD4QdS"
   },
   "outputs": [],
   "source": [
    "# Define traning pipeline\n",
    "bow = CountVectorizer(min_df=0.1, stop_words='english')\n",
    "\n",
    "pipe = # your code here\n",
    "\n",
    "# Fit on train data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test data (compute accuracy)\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4LZD-KT4QdT"
   },
   "source": [
    "#### 3.2 Tf-Idf\n",
    "\n",
    "Let's repeat the same procedure, but for tf-idf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8FurFH7_4QdT"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define traning pipeline\n",
    "tf_idf = TfidfVectorizer(sublinear_tf=True, min_df=0.1, stop_words='english')\n",
    "\n",
    "pipe = # your code here\n",
    "\n",
    "\n",
    "# Fit\n",
    "# your code here\n",
    "\n",
    "# Evaluate on test\n",
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
