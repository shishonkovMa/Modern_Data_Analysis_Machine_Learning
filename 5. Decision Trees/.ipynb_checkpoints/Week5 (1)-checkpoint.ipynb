{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73f4afc82ac5eb796497b27661b2e64e",
     "grade": false,
     "grade_id": "cell-ae30484898a90983",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b966d402a5a70fab19daf7aceb6e6fbe",
     "grade": false,
     "grade_id": "cell-76f53f536a715153",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is programming assignment for week 5. In this assignment you will be solving classification task. \n",
    "\n",
    "### Grading\n",
    "The assignment contains both automatically graded and peer reviewed tasks. \n",
    "\n",
    "**Automatic grading**\\\n",
    "After you finish solving all the tasks restart the kernel (`kernel -> restart`) and and click button `Validate` to check that everything works as expected. Afterwards, you can submit your work.\n",
    "\n",
    "\n",
    "\n",
    "**Peer Review**\\\n",
    "Some of the tasks cannot be checked automatically,  therefore, we'll be using peer review. Please, download this notebook with solutions (`File → Download as → Notebook (.ipynb)`) and submit it for peer review. Each peer reviewed task contains grading instructions. \n",
    "\n",
    "\n",
    "\n",
    "## Part 1. Let's train some decision trees. <a class=\"anchor\" id=\"part1\"></a>\n",
    "\n",
    "In this part, we will do the simplest preprocessig of the dataset and train decision trees. In the task, you are supposed to predict whether income of a person exceeds \\$50K/year. The target variable is equal to `1` if a person earns > \\$50k/year and `0` otherwise. \n",
    "\n",
    "As an evaluation criterion, we will be using $F_1$score. As you know, it is a weighted average of precision and recall. We are not using accuracy, because the dataset is imbalanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2247f6fbdeacd1a3b5d7fd85a425048",
     "grade": false,
     "grade_id": "cell-1a1e843b43cccdb6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_years</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  education  education_years      marital_status  \\\n",
       "0   39         State-gov  Bachelors               13       Never-married   \n",
       "1   50  Self-emp-not-inc  Bachelors               13  Married-civ-spouse   \n",
       "2   38           Private    HS-grad                9            Divorced   \n",
       "3   53           Private       11th                7  Married-civ-spouse   \n",
       "4   28           Private  Bachelors               13  Married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race     sex  capital_gain  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male          2174   \n",
       "1    Exec-managerial        Husband  White    Male             0   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male             0   \n",
       "3  Handlers-cleaners        Husband  Black    Male             0   \n",
       "4     Prof-specialty           Wife  Black  Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week native_country  target  \n",
       "0             0              40  United-States     0.0  \n",
       "1             0              13  United-States     0.0  \n",
       "2             0              40  United-States     0.0  \n",
       "3             0              40  United-States     0.0  \n",
       "4             0              40           Cuba     0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('https://github.com/mbburova/MDS/raw/main/week5_train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d49a747054b4f1419b46fe18822bee7d",
     "grade": false,
     "grade_id": "cell-84c65c97c89f7c75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tr, val = train_test_split(train_data, test_size=0.4, random_state=42)\n",
    "\n",
    "y_train = tr.target\n",
    "y_valid = val.target\n",
    "X_train = tr.drop(['target'], axis=1)\n",
    "X_valid = val.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "210b94f03d658eb2f945598cff06fb60",
     "grade": false,
     "grade_id": "cell-cfd6b8c9e0a01674",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"task1\"></a>\n",
    "\n",
    "---\n",
    "**Task 1** [1 pt] Create `column_transformer` which has the following steps:\n",
    "- fills all the missing values \n",
    "- encodes all the categorical features using OHE \n",
    "- scales numerical features.\n",
    "\n",
    "P.S. note, that you'll have to import all the required modules yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7a8657187d0724ac6605b1401b40d9c",
     "grade": false,
     "grade_id": "cell-72d8346d6028cb1d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "categ_columns = X_train.columns[X_train.dtypes == \"object\"].tolist()\n",
    "numeric_columns = X_train[[c for c in X_train.columns if c not in categ_columns]].columns.tolist()\n",
    "\n",
    "categ_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    OneHotEncoder(),\n",
    ")\n",
    "\n",
    "numeric_pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    ")\n",
    "\n",
    "column_transformer = ColumnTransformer([\n",
    " ('categ', categ_pipe, categ_columns),\n",
    " ('numeric', numeric_pipe, numeric_columns)],\n",
    "remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36c9c5802ffe52fa0a21f3cc0bc41e93",
     "grade": true,
     "grade_id": "cell-183f2ac417f75d76",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_transformed = column_transformer.fit_transform(X_train)\n",
    "X_transformed.shape\n",
    "\n",
    "X_transformed = column_transformer.fit_transform(X_train)\n",
    "assert X_transformed.shape[0] == 19536\n",
    "assert X_transformed.shape[1] == 104"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f0d7f88a9241e795223a173c45a51f03",
     "grade": false,
     "grade_id": "cell-fb4d3801b5f35b11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"task2\"></a>\n",
    "\n",
    "---\n",
    "**Task 2** [1 pt] Create a function `tree_pipe`, which given a maximal tree depth returns a pipeline with two steps:\n",
    "\n",
    "1. Column transformer (defined above)\n",
    "2. DecisionTreeClassfier with the required `max_depth` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3862785750a99944c053f9d5e0b8b339",
     "grade": false,
     "grade_id": "cell-b9de0824900552ec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "def tree_pipe(max_depth):\n",
    "    # YOUR CODE HERE\n",
    "    pipeline = Pipeline([\n",
    "        (\"column_transformer\", column_transformer),\n",
    "        (\"estimator\", DecisionTreeClassifier(max_depth=max_depth))\n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e60c8560b3230266728aba428e5a9337",
     "grade": true,
     "grade_id": "cell-c542e20f3e709f98",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_pipe = tree_pipe(1)\n",
    "\n",
    "test_pipe = tree_pipe(12)\n",
    "tree = test_pipe.steps[1][1]\n",
    "assert tree.max_depth == 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf6de67039590f3d54c06be163f3d152",
     "grade": false,
     "grade_id": "cell-52d80521f0a0cbf9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"task3\"></a>\n",
    "\n",
    "---\n",
    "**Task 3** [Peer Reviewed] Fit decision trees of different depth (from 1 to 100) using the function from the **task 2**. For each depth calculate $F_1$score on the train and validation datasets. Draw a plot, how both scores depend on the maximal tree depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a6226b71197ff52bd4da78c2060b6c4",
     "grade": false,
     "grade_id": "cell-d9d8ea084313b76d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# YOUR CODE HERE\n",
    "depth = [i for i in range(1, 100+1)]\n",
    "f1_score_train = []\n",
    "f1_score_valid = []\n",
    "for max_depth in range(1, 100+1):\n",
    "    p = tree_pipe(max_depth)\n",
    "    p.fit(X_train, y_train)\n",
    "    train_pred, valid_pred = p.predict(X_train), p.predict(X_valid)\n",
    "    f1_score_train.append(f1_score(train_pred, y_train))\n",
    "    f1_score_valid.append(f1_score(valid_pred, y_valid))\n",
    "    \n",
    "plt.plot(depth, f1_score_train, label=\"train\")\n",
    "plt.plot(depth, f1_score_valid, label=\"valid\")\n",
    "\n",
    "# plt.xscale(\"log\")\n",
    "plt.xlabel(\"depth\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.grid()\n",
    "plt.title('The dependence of score on the maximum depth')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c0de7b5576d63c76a04fccd52f15512",
     "grade": true,
     "grade_id": "cell-8d7c2fabbc41326a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Let's compete. <a class=\"anchor\" id=\"part2\"></a>\n",
    "\n",
    "In this second part of the assignment your task will be straightforward: achieve the best possible score on the test set. To make everything fair, we will be using [Kaggle competition](https://www.kaggle.com/c/predict-income-group). \n",
    "\n",
    "At this stage you are free to use any models or preprocessing methods you want. You can use assignemnts from the previous weeks as an inspiration!\n",
    "\n",
    "Below you can see how the test dataset can be loaded.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_years</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass     education  education_years      marital_status  \\\n",
       "0   25    Private          11th                7       Never-married   \n",
       "1   38    Private       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  Some-college               10  Married-civ-spouse   \n",
       "4   18        NaN  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race     sex  capital_gain  capital_loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                NaN    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours_per_week native_country  \n",
       "0              40  United-States  \n",
       "1              50  United-States  \n",
       "2              40  United-States  \n",
       "3              40  United-States  \n",
       "4              30  United-States  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('https://github.com/mbburova/MDS/raw/main/week5_test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR PREPROCESSING AND MODELS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's go from the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_years</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass   education  education_years      marital_status  \\\n",
       "0       39         State-gov   Bachelors               13       Never-married   \n",
       "1       50  Self-emp-not-inc   Bachelors               13  Married-civ-spouse   \n",
       "2       38           Private     HS-grad                9            Divorced   \n",
       "3       53           Private        11th                7  Married-civ-spouse   \n",
       "4       28           Private   Bachelors               13  Married-civ-spouse   \n",
       "...    ...               ...         ...              ...                 ...   \n",
       "32556   27           Private  Assoc-acdm               12  Married-civ-spouse   \n",
       "32557   40           Private     HS-grad                9  Married-civ-spouse   \n",
       "32558   58           Private     HS-grad                9             Widowed   \n",
       "32559   22           Private     HS-grad                9       Never-married   \n",
       "32560   52      Self-emp-inc     HS-grad                9  Married-civ-spouse   \n",
       "\n",
       "              occupation   relationship   race     sex  capital_gain  \\\n",
       "0           Adm-clerical  Not-in-family  White    Male          2174   \n",
       "1        Exec-managerial        Husband  White    Male             0   \n",
       "2      Handlers-cleaners  Not-in-family  White    Male             0   \n",
       "3      Handlers-cleaners        Husband  Black    Male             0   \n",
       "4         Prof-specialty           Wife  Black  Female             0   \n",
       "...                  ...            ...    ...     ...           ...   \n",
       "32556       Tech-support           Wife  White  Female             0   \n",
       "32557  Machine-op-inspct        Husband  White    Male             0   \n",
       "32558       Adm-clerical      Unmarried  White  Female             0   \n",
       "32559       Adm-clerical      Own-child  White    Male             0   \n",
       "32560    Exec-managerial           Wife  White  Female         15024   \n",
       "\n",
       "       capital_loss  hours_per_week native_country  target  \n",
       "0                 0              40  United-States     0.0  \n",
       "1                 0              13  United-States     0.0  \n",
       "2                 0              40  United-States     0.0  \n",
       "3                 0              40  United-States     0.0  \n",
       "4                 0              40           Cuba     0.0  \n",
       "...             ...             ...            ...     ...  \n",
       "32556             0              38  United-States     0.0  \n",
       "32557             0              40  United-States     1.0  \n",
       "32558             0              40  United-States     0.0  \n",
       "32559             0              20  United-States     0.0  \n",
       "32560             0              40  United-States     1.0  \n",
       "\n",
       "[32561 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                   0\n",
       "workclass          1836\n",
       "education             0\n",
       "education_years       0\n",
       "marital_status        0\n",
       "occupation         1843\n",
       "relationship          0\n",
       "race                  0\n",
       "sex                   0\n",
       "capital_gain          0\n",
       "capital_loss          0\n",
       "hours_per_week        0\n",
       "native_country      583\n",
       "target                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education_years</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.581647</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>40.437456</td>\n",
       "      <td>0.240810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.640433</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.347429</td>\n",
       "      <td>0.427581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  education_years  capital_gain  capital_loss  \\\n",
       "count  32561.000000     32561.000000  32561.000000  32561.000000   \n",
       "mean      38.581647        10.080679   1077.648844     87.303830   \n",
       "std       13.640433         2.572720   7385.292085    402.960219   \n",
       "min       17.000000         1.000000      0.000000      0.000000   \n",
       "25%       28.000000         9.000000      0.000000      0.000000   \n",
       "50%       37.000000        10.000000      0.000000      0.000000   \n",
       "75%       48.000000        12.000000      0.000000      0.000000   \n",
       "max       90.000000        16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours_per_week        target  \n",
       "count    32561.000000  32561.000000  \n",
       "mean        40.437456      0.240810  \n",
       "std         12.347429      0.427581  \n",
       "min          1.000000      0.000000  \n",
       "25%         40.000000      0.000000  \n",
       "50%         40.000000      0.000000  \n",
       "75%         45.000000      0.000000  \n",
       "max         99.000000      1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30725</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>30718</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>31978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>22696</td>\n",
       "      <td>10501</td>\n",
       "      <td>14976</td>\n",
       "      <td>4140</td>\n",
       "      <td>13193</td>\n",
       "      <td>27816</td>\n",
       "      <td>21790</td>\n",
       "      <td>29170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass education      marital_status      occupation relationship  \\\n",
       "count      30725     32561               32561           30718        32561   \n",
       "unique         8        16                   7              14            6   \n",
       "top      Private   HS-grad  Married-civ-spouse  Prof-specialty      Husband   \n",
       "freq       22696     10501               14976            4140        13193   \n",
       "\n",
       "         race    sex native_country  \n",
       "count   32561  32561          31978  \n",
       "unique      5      2             41  \n",
       "top     White   Male  United-States  \n",
       "freq    27816  21790          29170  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[categ_columns].describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with numerical features. If everything is clear with age, then the presence of a sign of years of study could be encoded into a categorical variable: secondary education, college, etc. In order to more clearly divide people into subgroups.\n",
    "Fortunately, our dataset already has such a breakdown \"education\". Therefore, you can safely delete the column \"education_years\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop('education_years', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables \"capital_gain\" and \"capital_loss\" can be converted into a single variable \"capital_change\". Because there cannot be a total loss and a total gain at the same time. Just subtract one from the other. There will be either a negative value or a positive one. Which will speak about the size of the cumulative increase. Either loss or gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['capital_change'] = train_data['capital_gain'] - train_data['capital_loss']\n",
    "train_data.drop(['capital_gain', 'capital_loss'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think about what can be done with the \"hours_per_week\" feature. To begin with, let's look at its distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_data.hours_per_week, bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that most of the people in our sample work a standard full day - 40 hours a week. The rest are distributed around this value. Someone works a little, and someone plows like a damn. There are two suggestions:\n",
    "1. Remove extremely high and extremely low values, because there are very few people in the sample who work on such schedules. Which can be an excuse not to identify this dependency by the model. \n",
    "2. Divide into categories: little work, part-time, rate, works a lot, etc. Something like that. To get a more explicit difference.\n",
    "\n",
    "However, for now I propose to leave this variable unchanged. You can always go back to them.\n",
    "\n",
    "Now let's move on to categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30725</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>30718</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>31978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>22696</td>\n",
       "      <td>10501</td>\n",
       "      <td>14976</td>\n",
       "      <td>4140</td>\n",
       "      <td>13193</td>\n",
       "      <td>27816</td>\n",
       "      <td>21790</td>\n",
       "      <td>29170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass education      marital_status      occupation relationship  \\\n",
       "count      30725     32561               32561           30718        32561   \n",
       "unique         8        16                   7              14            6   \n",
       "top      Private   HS-grad  Married-civ-spouse  Prof-specialty      Husband   \n",
       "freq       22696     10501               14976            4140        13193   \n",
       "\n",
       "         race    sex native_country  \n",
       "count   32561  32561          31978  \n",
       "unique      5      2             41  \n",
       "top     White   Male  United-States  \n",
       "freq    27816  21790          29170  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[categ_columns].describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bachelors',\n",
       " 'HS-grad',\n",
       " '11th',\n",
       " 'Masters',\n",
       " '9th',\n",
       " 'Some-college',\n",
       " 'Assoc-acdm',\n",
       " 'Assoc-voc',\n",
       " '7th-8th',\n",
       " 'Doctorate',\n",
       " 'Prof-school',\n",
       " '5th-6th',\n",
       " '10th',\n",
       " '1st-4th',\n",
       " 'Preschool',\n",
       " '12th']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.education.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, there are no questions about categorical variables. Almost all signs do not have so many unique values. \n",
    "\n",
    "However, it would be possible to finalize the issue with \"education\" and, for example, merge some values into a single whole, to reduce fragmentation. But there are no good reasons for this yet. Let's leave it as it is.\n",
    "\n",
    "There are two questions about categorical values. These are missing values and a large spread of unique values in the \"native_country\" attribute. Let's look at them.\n",
    "\n",
    "Let's start with the first one. Missing values. They are in three columns: workclass, occupation and native_country. Let's look at the first one: workclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>target</th>\n",
       "      <th>capital_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>60</td>\n",
       "      <td>South</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32530</th>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>55</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32531</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Female</td>\n",
       "      <td>99</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32539</th>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>10</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32541</th>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Separated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32542</th>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1836 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass     education         marital_status occupation  \\\n",
       "27      54       NaN  Some-college     Married-civ-spouse        NaN   \n",
       "61      32       NaN       7th-8th  Married-spouse-absent        NaN   \n",
       "69      25       NaN  Some-college          Never-married        NaN   \n",
       "77      67       NaN          10th     Married-civ-spouse        NaN   \n",
       "106     17       NaN          10th          Never-married        NaN   \n",
       "...    ...       ...           ...                    ...        ...   \n",
       "32530   35       NaN     Bachelors     Married-civ-spouse        NaN   \n",
       "32531   30       NaN     Bachelors          Never-married        NaN   \n",
       "32539   71       NaN     Doctorate     Married-civ-spouse        NaN   \n",
       "32541   41       NaN       HS-grad              Separated        NaN   \n",
       "32542   72       NaN       HS-grad     Married-civ-spouse        NaN   \n",
       "\n",
       "        relationship                race     sex  hours_per_week  \\\n",
       "27           Husband  Asian-Pac-Islander    Male              60   \n",
       "61     Not-in-family               White    Male              40   \n",
       "69         Own-child               White    Male              40   \n",
       "77           Husband               White    Male               2   \n",
       "106        Own-child               White  Female              32   \n",
       "...              ...                 ...     ...             ...   \n",
       "32530           Wife               White  Female              55   \n",
       "32531  Not-in-family  Asian-Pac-Islander  Female              99   \n",
       "32539        Husband               White    Male              10   \n",
       "32541  Not-in-family               Black  Female              32   \n",
       "32542        Husband               White    Male              25   \n",
       "\n",
       "      native_country  target  capital_change  \n",
       "27             South     1.0               0  \n",
       "61               NaN     0.0               0  \n",
       "69     United-States     0.0               0  \n",
       "77     United-States     0.0               0  \n",
       "106    United-States     0.0           34095  \n",
       "...              ...     ...             ...  \n",
       "32530  United-States     1.0               0  \n",
       "32531  United-States     0.0               0  \n",
       "32539  United-States     1.0               0  \n",
       "32541  United-States     0.0               0  \n",
       "32542  United-States     0.0               0  \n",
       "\n",
       "[1836 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data.workclass.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think it is logical to restore the values in the \"workclass\" column depending on the value of the \"occupation\" column. However, you can notice that if there is a missing value in one of the columns, then it is also missing in the other. Let's find out how many such lines there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "workclass         1836\n",
       "education            0\n",
       "marital_status       0\n",
       "occupation        1836\n",
       "relationship         0\n",
       "race                 0\n",
       "sex                  0\n",
       "hours_per_week       0\n",
       "native_country      27\n",
       "target               0\n",
       "capital_change       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data.workclass.isna()].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a result. \n",
    "Almost all rows in which the value \"occupation\" is omitted (1836 out of 1843) enclose the missing values in the \"workclass\" column as well. Our assumption was confirmed. We do not know anything about the working class and employment of 1836 people from our sample. Which, you must agree, plays an important role in the approximate understanding of the amount of cash payments to these people.\n",
    "\n",
    "And to understand more or less than 50 thousand dollars a year a person earns, depending on the marital status, relationship, race or other similar signs - agree, it is almost impossible\n",
    "\n",
    "Also, replacing missing values in these columns based on groupings is a very unfounded idea.\n",
    "I don't see any other choice but to delete rows with missing values in these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 0\n",
       "workclass           0\n",
       "education           0\n",
       "marital_status      0\n",
       "occupation          0\n",
       "relationship        0\n",
       "race                0\n",
       "sex                 0\n",
       "hours_per_week      0\n",
       "native_country    556\n",
       "target              0\n",
       "capital_change      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dropna(how='any', subset=['workclass', 'occupation'], inplace=True)\n",
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It remains to deal with the features of the countries. I think a good option to replace such a wide variety of categorical feature would be a description of belonging to a certain geographical location: Eupropa, Asia, North America, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.native_country.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have not found such databases on the Internet where it would be possible to determine belonging to a continent or a basin of countries by the name of a country. There is an option to parse this data from resources, such as Wikipedia or others. But this is already a super task, and we are not chasing the Kaggle grandmaster here.\n",
    "\n",
    "There is an option to manually mark up the data. However, this is a bad idea, because new countries may meet in the test set that will break the mechanism of the algorithm.\n",
    "\n",
    "Now replace the missing values in the countries column with the most common values, depending on the grouping based on \"race\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race\n",
       "Amer-Indian-Eskimo    United-States\n",
       "Asian-Pac-Islander    United-States\n",
       "Black                 United-States\n",
       "Other                 United-States\n",
       "White                 United-States\n",
       "Name: native_country, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(by=['race'])['native_country'].apply(lambda v: v.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we can see that in any group the most common country is \"United-States\". Let's replace the missing values with the result we received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.fillna(value='United-States')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's divide the data and start training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(['target'], axis=1)\n",
    "y_train = train_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_columns = X_train.columns[X_train.dtypes == \"object\"].tolist()\n",
    "numeric_columns = X_train[[c for c in X_train.columns if c not in categ_columns]].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>capital_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>2174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>15024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30718 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass   education      marital_status  \\\n",
       "0       39         State-gov   Bachelors       Never-married   \n",
       "1       50  Self-emp-not-inc   Bachelors  Married-civ-spouse   \n",
       "2       38           Private     HS-grad            Divorced   \n",
       "3       53           Private        11th  Married-civ-spouse   \n",
       "4       28           Private   Bachelors  Married-civ-spouse   \n",
       "...    ...               ...         ...                 ...   \n",
       "32556   27           Private  Assoc-acdm  Married-civ-spouse   \n",
       "32557   40           Private     HS-grad  Married-civ-spouse   \n",
       "32558   58           Private     HS-grad             Widowed   \n",
       "32559   22           Private     HS-grad       Never-married   \n",
       "32560   52      Self-emp-inc     HS-grad  Married-civ-spouse   \n",
       "\n",
       "              occupation   relationship   race     sex  hours_per_week  \\\n",
       "0           Adm-clerical  Not-in-family  White    Male              40   \n",
       "1        Exec-managerial        Husband  White    Male              13   \n",
       "2      Handlers-cleaners  Not-in-family  White    Male              40   \n",
       "3      Handlers-cleaners        Husband  Black    Male              40   \n",
       "4         Prof-specialty           Wife  Black  Female              40   \n",
       "...                  ...            ...    ...     ...             ...   \n",
       "32556       Tech-support           Wife  White  Female              38   \n",
       "32557  Machine-op-inspct        Husband  White    Male              40   \n",
       "32558       Adm-clerical      Unmarried  White  Female              40   \n",
       "32559       Adm-clerical      Own-child  White    Male              20   \n",
       "32560    Exec-managerial           Wife  White  Female              40   \n",
       "\n",
       "      native_country  capital_change  \n",
       "0      United-States            2174  \n",
       "1      United-States               0  \n",
       "2      United-States               0  \n",
       "3      United-States               0  \n",
       "4               Cuba               0  \n",
       "...              ...             ...  \n",
       "32556  United-States               0  \n",
       "32557  United-States               0  \n",
       "32558  United-States               0  \n",
       "32559  United-States               0  \n",
       "32560  United-States           15024  \n",
       "\n",
       "[30718 rows x 11 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    OneHotEncoder(handle_unknown='ignore'),\n",
    ")\n",
    "\n",
    "numeric_pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    ")\n",
    "\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('categ', categ_pipe, categ_columns),\n",
    "    ('numeric', numeric_pipe, numeric_columns)],\n",
    "remainder='drop')#'passthrough')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        (\"column_transformer\", column_transformer),\n",
    "        (\"estimator\", DecisionTreeClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "135 fits failed out of a total of 600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1101, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/jupyter-mashishonkov@edu.h-c77de/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.424268   0.424268   0.424268   0.424268   0.424268   0.424268\n",
      " 0.61513517 0.61524469 0.61524469 0.61513517 0.61524469 0.61524469\n",
      " 0.64080891 0.6408178  0.64096307 0.64106952 0.64132049 0.64116783\n",
      " 0.66655461 0.67150471 0.67142933 0.67050771 0.67089784 0.67035146\n",
      " 0.66926132 0.67177806 0.67340929 0.67121421 0.67241038 0.67201047\n",
      " 0.67600757 0.67714323 0.6781945  0.67705541 0.67318972 0.67103429\n",
      " 0.6766034  0.68085608 0.68321813 0.68116402 0.67797594 0.6776041\n",
      " 0.67756674 0.68213743 0.68680078 0.6844582  0.68219264 0.67964628\n",
      " 0.67756674 0.6830483  0.69002061 0.69012269 0.68923297 0.68635302\n",
      " 0.67756674 0.68309607 0.69002061 0.69032478 0.68986521 0.68737608\n",
      "        nan        nan 0.65312785        nan 0.65317561 0.6541267\n",
      " 0.65412539 0.6540782  0.65364991 0.6536008         nan        nan\n",
      "        nan        nan        nan 0.65501644 0.65444011        nan\n",
      " 0.65516015 0.65453614        nan        nan 0.65322288        nan\n",
      " 0.65312875 0.6541267  0.65403042 0.6540782  0.65364991 0.65364991\n",
      "        nan        nan        nan        nan        nan 0.65501644\n",
      " 0.65520811        nan 0.65511198 0.65511294        nan        nan\n",
      " 0.65322288        nan 0.65307857 0.6541267  0.65403042 0.6540782\n",
      " 0.65364991 0.65364991        nan        nan        nan        nan\n",
      "        nan 0.65501644 0.65492319        nan 0.65511371 0.65511198]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;column_transformer&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;categ&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                          SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                         (&#x27;onehotencoder&#x27;,\n",
       "                                                                                          OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                         [&#x27;workclass&#x27;,\n",
       "                                                                          &#x27;education&#x27;,\n",
       "                                                                          &#x27;marital_status&#x27;,\n",
       "                                                                          &#x27;occupation&#x27;,\n",
       "                                                                          &#x27;relationship&#x27;,\n",
       "                                                                          &#x27;race&#x27;,\n",
       "                                                                          &#x27;sex&#x27;,\n",
       "                                                                          &#x27;native_country&#x27;]),\n",
       "                                                                        (&#x27;numeri...\n",
       "             param_grid=[{&#x27;estimator&#x27;: [DecisionTreeClassifier(max_depth=40,\n",
       "                                                               max_leaf_nodes=200)],\n",
       "                          &#x27;estimator__max_depth&#x27;: [3, 5, 7, 10, 12, 15, 17, 20,\n",
       "                                                   30, 40],\n",
       "                          &#x27;estimator__max_leaf_nodes&#x27;: [70, 100, 150, 200, 250,\n",
       "                                                        300]},\n",
       "                         {&#x27;estimator&#x27;: [LogisticRegression()],\n",
       "                          &#x27;estimator__max_iter&#x27;: [100, 250, 500],\n",
       "                          &#x27;estimator__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;,\n",
       "                                                 &#x27;none&#x27;],\n",
       "                          &#x27;estimator__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;,\n",
       "                                                &#x27;liblinear&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;]}],\n",
       "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;column_transformer&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;categ&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                          SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                         (&#x27;onehotencoder&#x27;,\n",
       "                                                                                          OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                         [&#x27;workclass&#x27;,\n",
       "                                                                          &#x27;education&#x27;,\n",
       "                                                                          &#x27;marital_status&#x27;,\n",
       "                                                                          &#x27;occupation&#x27;,\n",
       "                                                                          &#x27;relationship&#x27;,\n",
       "                                                                          &#x27;race&#x27;,\n",
       "                                                                          &#x27;sex&#x27;,\n",
       "                                                                          &#x27;native_country&#x27;]),\n",
       "                                                                        (&#x27;numeri...\n",
       "             param_grid=[{&#x27;estimator&#x27;: [DecisionTreeClassifier(max_depth=40,\n",
       "                                                               max_leaf_nodes=200)],\n",
       "                          &#x27;estimator__max_depth&#x27;: [3, 5, 7, 10, 12, 15, 17, 20,\n",
       "                                                   30, 40],\n",
       "                          &#x27;estimator__max_leaf_nodes&#x27;: [70, 100, 150, 200, 250,\n",
       "                                                        300]},\n",
       "                         {&#x27;estimator&#x27;: [LogisticRegression()],\n",
       "                          &#x27;estimator__max_iter&#x27;: [100, 250, 500],\n",
       "                          &#x27;estimator__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;,\n",
       "                                                 &#x27;none&#x27;],\n",
       "                          &#x27;estimator__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;,\n",
       "                                                &#x27;liblinear&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;]}],\n",
       "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;column_transformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categ&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehotencoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;workclass&#x27;, &#x27;education&#x27;,\n",
       "                                                   &#x27;marital_status&#x27;,\n",
       "                                                   &#x27;occupation&#x27;, &#x27;relationship&#x27;,\n",
       "                                                   &#x27;race&#x27;, &#x27;sex&#x27;,\n",
       "                                                   &#x27;native_country&#x27;]),\n",
       "                                                 (&#x27;numeric&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;hours_per_week&#x27;,\n",
       "                                                   &#x27;capital_change&#x27;])])),\n",
       "                (&#x27;estimator&#x27;, DecisionTreeClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">column_transformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;categ&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;workclass&#x27;, &#x27;education&#x27;, &#x27;marital_status&#x27;,\n",
       "                                  &#x27;occupation&#x27;, &#x27;relationship&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;,\n",
       "                                  &#x27;native_country&#x27;]),\n",
       "                                (&#x27;numeric&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;age&#x27;, &#x27;hours_per_week&#x27;, &#x27;capital_change&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categ</label><div class=\"sk-toggleable__content\"><pre>[&#x27;workclass&#x27;, &#x27;education&#x27;, &#x27;marital_status&#x27;, &#x27;occupation&#x27;, &#x27;relationship&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;, &#x27;native_country&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numeric</label><div class=\"sk-toggleable__content\"><pre>[&#x27;age&#x27;, &#x27;hours_per_week&#x27;, &#x27;capital_change&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('column_transformer',\n",
       "                                        ColumnTransformer(transformers=[('categ',\n",
       "                                                                         Pipeline(steps=[('simpleimputer',\n",
       "                                                                                          SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                         ('onehotencoder',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                         ['workclass',\n",
       "                                                                          'education',\n",
       "                                                                          'marital_status',\n",
       "                                                                          'occupation',\n",
       "                                                                          'relationship',\n",
       "                                                                          'race',\n",
       "                                                                          'sex',\n",
       "                                                                          'native_country']),\n",
       "                                                                        ('numeri...\n",
       "             param_grid=[{'estimator': [DecisionTreeClassifier(max_depth=40,\n",
       "                                                               max_leaf_nodes=200)],\n",
       "                          'estimator__max_depth': [3, 5, 7, 10, 12, 15, 17, 20,\n",
       "                                                   30, 40],\n",
       "                          'estimator__max_leaf_nodes': [70, 100, 150, 200, 250,\n",
       "                                                        300]},\n",
       "                         {'estimator': [LogisticRegression()],\n",
       "                          'estimator__max_iter': [100, 250, 500],\n",
       "                          'estimator__penalty': ['l1', 'l2', 'elasticnet',\n",
       "                                                 'none'],\n",
       "                          'estimator__solver': ['newton-cg', 'lbfgs',\n",
       "                                                'liblinear', 'sag', 'saga']}],\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {'estimator': [DecisionTreeClassifier()], \n",
    "    'estimator__max_depth': [3, 5, 7, 10, 12, 15, 17, 20, 30, 40],\n",
    "    'estimator__max_leaf_nodes': [70, 100, 150, 200, 250, 300]},\n",
    "    {'estimator': [LogisticRegression()],\n",
    "    'estimator__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'estimator__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'estimator__max_iter': [100, 250, 500]}\n",
    "]\n",
    "\n",
    "grid_pipe = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='f1')\n",
    "grid_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69032477994867\n",
      "DecisionTreeClassifier(max_depth=40, max_leaf_nodes=200)\n"
     ]
    }
   ],
   "source": [
    "print(grid_pipe.best_score_)\n",
    "print(grid_pipe.best_estimator_.steps[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In view of the fact that I did not prescribe data preprocessing, we will make an exception and process the test data in the same way as the train. **Of course, except for those procedures that require fit_transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop('education_years', axis=1, inplace=True)\n",
    "test_data['capital_change'] = test_data['capital_gain'] - test_data['capital_loss']\n",
    "test_data.drop(['capital_gain', 'capital_loss'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pipe.best_estimator_.fit(X_train, y_train)\n",
    "y_pred = grid_pipe.best_estimator_.predict(test_data).astype(int)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see, how `csv` file with the prediction can be created and saved. This file can be later used to upload to Kaggle. Please note, that type of the prediction should be `integer`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we do not restrict you a lot in this task, we still ask you to stick to the following steps, which will be graded by your peers\n",
    "\n",
    "**Peer Review Grading.** Below you will find the list of criteria for peer review:\n",
    "1. Consider categorical features. Show which feature are categorical, check if all the categories are reasonable. Provide plots.\n",
    "2. Consider numerical features\n",
    "3. Fill missing values. \n",
    "4. Explore different hyperparameters of the decision trees (not only `max_depth`)\n",
    "5. Choose the best model using cross-validation or just validation\n",
    "6. Make a prediction on the test set.\n",
    "7. Try to make your code readable. Do not forget to leave comments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
